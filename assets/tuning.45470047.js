import{o as e,c as n,m as t,r as a,l as r,u as o}from"./vendor.1180558b.js";const s={class:"markdown-body"},i=[t('<blockquote><p>Linkis0.x version runs stably on the production environment of WeBank, and supports various businesses. Linkis1.0 is an optimized version of 0.x, and the related tuning logic has not changed, so this document will introduce several Linkis deployment and tuning suggestions. Due to limited space, this article cannot cover all optimization scenarios. Related tuning guides will also be supplemented and updated. Of course, we also hope that community users will provide suggestions for Linkis1.0 tuning documents.</p></blockquote><h2>1. Overview</h2><p>This document will introduce several tuning methods based on production experience, namely the selection of Jvm heap size during deployment in production, the setting of concurrency for task submission, and the introduction of task running resource application parameters. The parameter settings described in the document are not recommended parameter values. Users need to select the parameters according to their actual production environment.</p><h2>2. Jvm heap size tuning</h2><p>When installing Linkis, you can find the following variables in linkis-env.sh:</p><pre><code class="language-shell">SERVER_HEAP_SIZE=&quot;512M&quot;\n</code></pre><p>After setting this variable, it will be added to the java startup parameters of each microservice during installation to control the Jvm startup heap size. Although the xms and xmx parameters need to be set when java is started, they are usually set to the same value. In production, as the number of users increases, this parameter needs to be adjusted larger to meet the needs. Of course, setting a larger stack memory requires a larger server configuration. Also, single-machine deployment has limitations. In production, a distributed deployment method can be used to deploy different Linkis and DSS microservices on multiple servers. Meanwhile, you can adjust the stack size to meet production requirements.</p><h2>3. Tuning the concurrency of task submission</h2><p>Some Linkis task concurrency parameters will have a default value. In most scenarios, the default value can meet the demand, but sometimes it cannot, so it needs to be adjusted. This article will introduce several parameters for adjusting the concurrency of tasks to facilitate users to optimize concurrent tasks in production.</p><p>Since tasks are submitted by RPC, in the linkis-common/linkis-rpc module, you can configure the following parameters to increase the number of concurrent rpc:</p><pre><code class="language-shell">wds.linkis.rpc.receiver.asyn.consumer.thread.max=400\nwds.linkis.rpc.receiver.asyn.queue.size.max=5000\nwds.linkis.rpc.sender.asyn.consumer.thread.max=100\nwds.linkis.rpc.sender.asyn.queue.size.max=2000\n</code></pre><p>In the Linkis source code, we set a default value for the number of concurrent tasks, which can meet the needs in most scenarios. However, when a large number of concurrent tasks are submitted for execution in some scenarios, such as when Qualitis (another open source project of WeBank) is used for mass data verification, initCapacity and maxCapacity have not been upgraded to a configurable item in the current version. Users need to modify, by increasing the values of these two parameters, the number of concurrency. Of course, this also requires a higher server configuration.</p><pre><code class="language-java">  private val groupNameToGroups = new JMap[String, Group]\n  private val labelBuilderFactory = LabelBuilderFactoryContext.getLabelBuilderFactory\n\n  override def getOrCreateGroup(groupName: String): Group = {\n    if (!groupNameToGroups.containsKey(groupName)) synchronized {\n      val initCapacity = 100\n      val maxCapacity = 100\n      // 其它代码...\n        }\n      }\n</code></pre><h2>4. Resource settings related to task runtime</h2><p>When submitting a task to run on Yarn, Yarn provides a configurable interface. As a highly scalable framework, Linkis can also be configured to set resource configuration.</p><p>The related configuration of Spark and Hive are as follows:</p><p>Part of the Spark configuration in linkis-engineconn-plugins/engineconn-plugins, you can adjust the configuration to change the runtime environment of tasks submitted to Yarn. Due to limited space, such as more about Hive, Yarn configuration requires users to refer to the source code and the parameters documentation.</p><pre><code class="language-shell">&quot;spark.driver.memory&quot; = 2 //单位为G\n&quot;wds.linkis.driver.cores&quot; = 1\n&quot;spark.executor.memory&quot; = 4 //单位为G\n&quot;spark.executor.cores&quot; = 2\n&quot;spark.executor.instances&quot; = 3\n&quot;wds.linkis.rm.yarnqueue&quot; = &quot;default&quot;\n</code></pre>',18)],u={setup:(t,{expose:a})=>(a({frontmatter:{}}),(t,a)=>(e(),n("div",s,i)))},c={class:"markdown-body"},l=[t('<blockquote><p>Linkis0.x版本在微众银行生产上稳定运行，并支撑着各种业务，Linkis1.0作为0.x的优化版本，相关调优逻辑并没有改变，所以本文档会介绍几个生产上Linkis部署调优的建议，由于篇幅有限，本文并不能覆盖到所有的优化场景，相关调优指南也会补充更新，当然也希望社区用户为Linkis1.0的调优文档提出建议。</p></blockquote><h2>1. 概述</h2><p>        本文档将会按照生产的经验，介绍几个调优的手段，分别是生产上部署时Jvm堆大小选取，任务提交的并发量设置，任务运行资源申请参数介绍。文档中叙述的参数设置，并不是建议设置的参数值，用户需要根据自己真实地生产环境，对参数进行选取。</p><h2>2. Jvm堆大小调优</h2><p>        在安装Linkis时，可以在linkis-env.sh中找到以下变量：</p><pre><code class="language-shell">SERVER_HEAP_SIZE=&quot;512M&quot;\n</code></pre><p>        设置该变量，在安装后，会加入到每个微服务的java启动参数中，用来控制Jvm启动堆大小，虽然在java启动时，需要设置xms和xmx两个参数，但是通常会设置成一样的值，在生产上，随着使用人数的增多，该参数需要调整大一些才能满足生产的需求。当然设置更大的堆栈内存，需要更大的服务器配置，当然，单机部署存在局限性，在生产上，可以采用分布式部署的方式，用多台服务器分别部署不同的Linkis和DSS微服务，同时调整堆栈大小，达到满足生产的需求。</p><h2>3. 任务提交的并发量调优</h2><p>        Linkis的一些任务并发参数都会有一个默认值，大多数场景下默认值都可以满足需求，但是有时，默认值并不能满足需求，所以需要通过改变参数的大小进行调整，本文会介绍几个调整任务并发的参数。方便用户对生产上的并发任务进行优化。</p><p>        因为任务的提交都是采用RPC的方式，在linkis-common/linkis-rpc模块中，可以通过配置如下几个参数提高rpc的并发数量：</p><pre><code class="language-shell">wds.linkis.rpc.receiver.asyn.consumer.thread.max=400\nwds.linkis.rpc.receiver.asyn.queue.size.max=5000\nwds.linkis.rpc.sender.asyn.consumer.thread.max=100\nwds.linkis.rpc.sender.asyn.queue.size.max=2000\n</code></pre><p>        在Linkis源码中，我们对提交任务的并发数设置了一个默认值，该值在绝大多数场景下都能很好的满足需求，但是在有些场景出现大量并发任务提交执行时，比如用Qualitis（微众银行另一款开源项目）进行大批量数据校验时，这个参数在目前的版本中并没有提升为可配置项，分别是initCapacity，maxCapacity两个参数，需要用户进行改造，提高这两个参数，可以提高并发数，当然也需要更高的服务器配置。</p><pre><code class="language-java">  private val groupNameToGroups = new JMap[String, Group]\n  private val labelBuilderFactory = LabelBuilderFactoryContext.getLabelBuilderFactory\n\n  override def getOrCreateGroup(groupName: String): Group = {\n    if (!groupNameToGroups.containsKey(groupName)) synchronized {\n      val initCapacity = 100\n      val maxCapacity = 100\n      // 其它代码...\n        }\n      }\n</code></pre><h2>4. 任务运行时资源设置</h2><p>        在提交任务运行在Yarn上时，Yarn提供了可配置的接口，Linkis作为一个可拓展性强的框架，同样也可以通过Linkis的配置来设置资源配置。<br>         Spark的相关配置和Hive的相关配置如下：<br> 在linkis-engineconn-plugins/engineconn-plugins里的Spark的部分配置，可以调整该配置改变提交到Yarn上的任务运行时环境，由于篇幅有限，如更多有关Hive，Yarn配置需要用户参考源码和参数文档:</p><pre><code class="language-shell">&quot;spark.driver.memory&quot; = 2 //单位为G\n&quot;wds.linkis.driver.cores&quot; = 1\n&quot;spark.executor.memory&quot; = 4 //单位为G\n&quot;spark.executor.cores&quot; = 2\n&quot;spark.executor.instances&quot; = 3\n&quot;wds.linkis.rm.yarnqueue&quot; = &quot;default&quot;\n</code></pre>',16)],p={setup:(t,{expose:a})=>(a({frontmatter:{}}),(t,a)=>(e(),n("div",c,l)))},d={setup(n){const t=a(localStorage.getItem("locale")||"en");return(n,a)=>"en"===t.value?(e(),r(o(u),{key:0})):(e(),r(o(p),{key:1}))}};export{d as default};
