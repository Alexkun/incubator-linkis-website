import{o as e,c as t,m as n,b as l,e as r,r as a,l as o,u as s}from"./vendor.1180558b.js";const i={class:"markdown-body"},u=[n("<h1>Introduction to Distributed Deployment Scheme</h1><p>Linkis’s stand-alone deployment is simple, but it cannot be used in a production environment, because too many processes on the same server will make the server too stressful. The choice of deployment plan is related to the company’s user scale, user habits, and the number of simultaneous users of the cluster. Generally speaking, we will choose the deployment method based on the number of simultaneous users using Linkis and the user’s preference for the execution engine.</p><h2>1.Multi-node deployment method reference</h2><p>Linkis1.0 still maintains the SpringCloud-based microservice architecture, in which each microservice supports multiple active deployment schemes. Of course, different microservices play different roles in the system. Some microservices are called frequently, and more It may be in a high load situation. *<em>On the machine where EngineConnManager is installed, the memory load of the machine will be relatively high because the user’s engine process will be started, and the load of other types of microservices on the machine will be relatively low.</em> *For this kind of microservices, we recommend starting multiple distributed deployments. The total resources dynamically used by Linkis can be calculated as follows.</p><p>EngineConnManager Total resources used = total memory + total number of cores = Number of people online at the same time * (All types of engines occupy memory) *maximum concurrency per user + number of people online at the same time * (total memory occupied by all types of engine conns) *maximum concurrency per user</p><p>For example, when only spark, hive, and python engines are used and the maximum concurrency of a single user is 1, 50 people are used at the same time, Spark’s driver memory is 1G, and Hive Client memory 1G, python client 1G, each engine uses 1 core, then it is 50 *(1+1+1)G * 1 + 50 *(1+1+1) cores*1 = 150G memory + 150 CPU cores.</p><p>During distributed deployment, the memory occupied by the microservice itself can be calculated according to each 2G memory. In the case of a large number of users, it is recommended to increase the memory of ps-publicservice to 6G, and it is recommended to reserve 10G of memory as a buffer. The following configuration assumes that <strong>each user starts two engines at the same time as an example</strong>. <strong>For a machine with 64G memory</strong>, the reference configuration is as follows:</p><ul><li>10-50 people online at the same time</li></ul><blockquote><p><strong>Server configuration recommended</strong> 4 servers, named S1, S2, S3, S4</p></blockquote><table><thead><tr><th>Service</th><th>Host name</th><th>Remark</th></tr></thead><tbody><tr><td>cg-engineconnmanager</td><td>S1, S2</td><td>Each machine is deployed separately</td></tr><tr><td>Other services</td><td>S3, S4</td><td>Eureka high availability deployment</td></tr></tbody></table><ul><li>50-100 people online at the same time</li></ul><blockquote><p><strong>Server configuration recommendation</strong>: 6 servers, named S1, S2, S3, S4, S5, S6</p></blockquote><table><thead><tr><th>Service</th><th>Host name</th><th>Remark</th></tr></thead><tbody><tr><td>cg-engineconnmanager</td><td>S1-S4</td><td>Each machine is deployed separately</td></tr><tr><td>Other services</td><td>S5, S6</td><td>Eureka high availability deployment</td></tr></tbody></table><ul><li>The number of simultaneous users 100-300</li></ul><p><strong>Recommended server configuration</strong>: 12 servers, named S1, S2…S12</p><table><thead><tr><th>Service</th><th>Host name</th><th>Remark</th></tr></thead><tbody><tr><td>cg-engineconnmanager</td><td>S1-S10</td><td>Each machine is deployed separately</td></tr><tr><td>Other services</td><td>S11, S12</td><td>Eureka high availability deployment</td></tr></tbody></table><ul><li>300-500 people at the same time</li></ul><blockquote><p><strong>Server configuration recommendation</strong>: 20 servers, named S1, S2…S20</p></blockquote><table><thead><tr><th>Service</th><th>Host name</th><th>Remark</th></tr></thead><tbody><tr><td>cg-engineconnmanager</td><td>S1-S18</td><td>Each machine is deployed separately</td></tr><tr><td>Other services</td><td>S19, S20</td><td>Eureka high-availability deployment, some microservices can be expanded if the request volume is tens of thousands, and the current active-active deployment can support thousands of users in the industry</td></tr></tbody></table><ul><li>More than 500 users at the same time (estimated based on 800 people online at the same time)</li></ul><blockquote><p><strong>Server configuration recommendation</strong>: 34 servers, named S1, S2…S34</p></blockquote><table><thead><tr><th>Service</th><th>Host name</th><th>Remark</th></tr></thead><tbody><tr><td>cg-engineconnmanager</td><td>S1-S32</td><td>Each machine is deployed separately</td></tr><tr><td>Other services</td><td>S33, S34</td><td>Eureka high-availability deployment, some microservices can be expanded if the request volume is tens of thousands, and the current active-active deployment can support thousands of users in the industry</td></tr></tbody></table><h2>2.Linkis microservices distributed deployment configuration parameters</h2><p>In linkis1.0, we have optimized and integrated the startup parameters. Some important startup parameters of each microservice are loaded through the conf/linkis-env.sh file, such as the microservice IP, port, registry address, etc. The way to modify the parameters has changed a little. Take the active-active deployment of the machines <strong>server1 and server2</strong> as an example, in order to allow eureka to register with each other.</p><p>On the server1 machine, you need to change the value in <strong>conf/linkis-env.sh</strong></p><p><code>EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/</code></p><p>change into:</p><p><code>EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/,http:/server2:port/eureka/</code></p><p>In the same way, on the server2 machine, you need to change the value in <strong>conf/linkis-env.sh</strong></p><p><code>EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/</code></p><p>change into:</p><p><code>EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/,http:/server1:port/eureka/</code></p><p>After the modification, start the microservice, enter the eureka registration interface from the web side, you can see that the microservice has been successfully registered to eureka, and the DS Replicas will also display the replica nodes adjacent to the cluster.</p>",33)],d={setup:(n,{expose:l})=>(l({frontmatter:{}}),(n,l)=>(e(),t("div",i,u)))};const c={class:"markdown-body"},h=[l("h1",null,"分布式部署方案介绍",-1),l("p",null,"Linkis的单机部署方式简单，但是不能用于生产环境，因为过多的进程在同一个服务器上会让服务器压力过大。 部署方案的选择，和公司的用户规模、用户使用习惯、集群同时使用人数都有关，一般来说，我们会以使用Linkis的同时使用人数和用户对执行引擎的偏好来做依据进行部署方式的选择。",-1),l("h2",null,"1、多节点部署方式参考",-1),l("p",null,"Linkis1.0仍然保持着基于SpringCloud的微服务架构，其中每个微服务都支持多活的部署方案，当然不同的微服务在系统中承担的角色不一样，有的微服务调用频率很高，更可能会处于高负荷的情况，**在安装EngineConnManager的机器上，由于会启动用户的引擎进程，机器的内存负载会比较高，其他类型的微服务对机器的负载则相对不会很高，**对于这类微服务我们建议启动多个进行分布式部署，Linkis动态使用的总资源可以按照如下方式计算。",-1),l("p",null,[l("strong",null,"EngineConnManager"),r("使用总资源 = 总内存 + 总核数 =")],-1),l("p",null,[l("strong",null,"同时在线人数 * (所有类型的引擎占用内存) *单用户最高并发数+ 同时在线人数 * (所有类型的引擎占用内存) *单用户最高并发数")],-1),l("p",null,"例如只使用spark、hive、python引擎且单用户最高并发数为1的情况下，同时使用人数50人，Spark的Driver内存1G，Hive Client内存1G，python client 1G，每个引擎都使用1个核，那么就是 50 *（1+1+1）G * 1 + 50 *(1+1+1)核*1 = 150G 内存 + 150 CPU核数。",-1),l("p",null,"分布式部署时微服务本身占用的内存可以按照每个2G计算，对于使用人数较多的情况下建议调大ps-publicservice的内存至6G，同时建议预留10G内存作为buffer。",-1),l("p",null,[r("以下配置假设"),l("strong",null,"每个用户同时启动两个引擎为例"),r("，"),l("strong",null,"对于64G内存的机器"),r("，参考配置如下：")],-1),l("ul",null,[l("li",null,"同时在线人数10-50")],-1),l("blockquote",null,[l("p",null,[l("strong",null,"服务器配置推荐"),r("4台服务器，分别命名为S1,S2,S3,S4")])],-1),l("table",null,[l("thead",null,[l("tr",null,[l("th",null,"Service"),l("th",null,"Host name"),l("th",null,"Remark")])]),l("tbody",null,[l("tr",null,[l("td",null,"cg-engineconnmanager"),l("td",null,"S1、S2"),l("td",null,"每台机器单独部署")]),l("tr",null,[l("td",null,"Other services"),l("td",null,"S3、S4"),l("td",null,"Eureka高可用部署")])])],-1),l("ul",null,[l("li",null,"同时在线人数50-100")],-1),l("blockquote",null,[l("p",null,[l("strong",null,"服务器配置推荐"),r(":6台服务器，分别命名为S1,S2,S3,S4,S5,S6")])],-1),l("table",null,[l("thead",null,[l("tr",null,[l("th",null,"Service"),l("th",null,"Host name"),l("th",null,"Remark")])]),l("tbody",null,[l("tr",null,[l("td",null,"cg-engineconnmanager"),l("td",null,"S1-S4"),l("td",null,"每台机器单独部署")]),l("tr",null,[l("td",null,"Other services"),l("td",null,"S5、S6"),l("td",null,"Eureka高可用部署")])])],-1),l("ul",null,[l("li",null,"同时使用人数 100-300")],-1),l("p",null,[l("strong",null,"服务器配置推荐"),r(":12台服务器，分别命名为S1,S2…S12")],-1),l("table",null,[l("thead",null,[l("tr",null,[l("th",null,"Service"),l("th",null,"Host name"),l("th",null,"Remark")])]),l("tbody",null,[l("tr",null,[l("td",null,"cg-engineconnmanager"),l("td",null,"S1-S10"),l("td",null,"每台机器单独部署")]),l("tr",null,[l("td",null,"Other services"),l("td",null,"S11、S12"),l("td",null,"Eureka高可用部署")])])],-1),l("ul",null,[l("li",null,"同时使用人数300-500")],-1),l("blockquote",null,[l("p",null,[l("strong",null,"服务器配置推荐"),r("：20台服务器，分别命名为S1,S2…S20")])],-1),l("table",null,[l("thead",null,[l("tr",null,[l("th",null,"Service"),l("th",null,"Host name"),l("th",null,"Remark")])]),l("tbody",null,[l("tr",null,[l("td",null,"cg-engineconnmanager"),l("td",null,"S1-S18"),l("td",null,"每台机器单独部署")]),l("tr",null,[l("td",null,"Other services"),l("td",null,"S19、S20"),l("td",null,"Eureka高可用部署，部分微服务如果请求量上万可以考虑扩容，目前双活部署可以支持行内上千用户使用")])])],-1),l("ul",null,[l("li",null,"同时使用人数500以上（按照同时在线800人估算）")],-1),l("blockquote",null,[l("p",null,[l("strong",null,"服务器配置推荐"),r("：34台服务器，分别命名为S1,S2…S34")])],-1),l("table",null,[l("thead",null,[l("tr",null,[l("th",null,"Service"),l("th",null,"Host name"),l("th",null,"Remark")])]),l("tbody",null,[l("tr",null,[l("td",null,"cg-engineconnmanager"),l("td",null,"S1-S32"),l("td",null,"每台机器单独部署")]),l("tr",null,[l("td",null,"Other services"),l("td",null,"S33、S34"),l("td",null,"Eureka高可用部署，部分微服务如果请求量上万可以考虑扩容，目前双活部署可以支持行内上千用户使用")])])],-1),l("h2",null,"2、Linkis微服务分布式部署配置参数",-1),l("p",null,"在linkis1.0中，我们对启动参数进行了优化和整合，各个微服务的部分重要的启动参数都通过conf/linkis-env.sh文件加载，例如微服务IP、端口、注册中心地址等，因此修改参数的方式发生了一点变化，以机器server1，server2双活部署为例，为了让eureka之间相互注册。",-1),l("p",null,[r("在server1的机器上，需要将"),l("strong",null,"conf/linkis-env.sh"),r("中的 "),l("code",null,"EUREKA\\_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/")],-1),l("p",null,"修改为：",-1),l("p",null,[l("code",null,"EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/,http:/server2:port/eureka/")],-1),l("p",null,[r("同理，在server2的机器上，需要将"),l("strong",null,"conf/linkis-env.sh"),r("中的")],-1),l("p",null,[l("code",null,"EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/")],-1),l("p",null,"修改为：",-1),l("p",null,[l("code",null,"EUREKA_URL=http://$EUREKA_INSTALL_IP:$EUREKA_PORT/eureka/,http:/server1:port/eureka/")],-1),l("p",null,"修改完之后启动微服务，从web端进入eureka注册界面，可以看到已经成功注册到eureka的微服务，并且DS Replicas也会显示集群相邻的副本节点。",-1),l("p",null,[l("img",{src:"/assets/distributed_deployment.d533f7c3.png",alt:""})],-1)],m={setup:(n,{expose:l})=>(l({frontmatter:{}}),(n,l)=>(e(),t("div",c,h)))},p={setup(t){const n=a(localStorage.getItem("locale")||"en");return(t,l)=>"en"===n.value?(e(),o(s(d),{key:0})):(e(),o(s(m),{key:1}))}};export{p as default};
