import{o as e,c as t,m as n,r as i,l as o,u as s}from"./vendor.1180558b.js";const l={class:"markdown-body"},a=[n('<h1>Linkis User Manual</h1><blockquote><p>Linkis provides a convenient interface for calling JAVA and SCALA. It can be used only by introducing the linkis-computation-client module. After 1.0, the method of submitting with Label is added. The following will introduce both ways that compatible with 0.X and newly added in 1.0.</p></blockquote><h2>1. Introduce dependent modules</h2><pre><code>&lt;dependency&gt;\n   &lt;groupId&gt;com.webank.wedatasphere.linkis&lt;/groupId&gt;\n   &lt;artifactId&gt;linkis-computation-client&lt;/artifactId&gt;\n   &lt;version&gt;${linkis.version}&lt;/version&gt;\n&lt;/dependency&gt;\nSuch as:\n&lt;dependency&gt;\n   &lt;groupId&gt;com.webank.wedatasphere.linkis&lt;/groupId&gt;\n   &lt;artifactId&gt;linkis-computation-client&lt;/artifactId&gt;\n   &lt;version&gt;1.0.0-RC1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><h2>2. Compatible with 0.X Execute method submission</h2><h3>2.1 Java test code</h3><p>Create the Java test class UJESClientImplTestJ. Refer to the comments to understand the purposes of those interfaces:</p><pre><code class="language-java">package com.webank.wedatasphere.linkis.client.test;\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.TokenAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfig;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClientImpl;\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobExecuteAction;\nimport com.webank.wedatasphere.linkis.ujes.client.request.ResultSetAction;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobExecuteResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobInfoResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobProgressResult;\nimport org.apache.commons.io.IOUtils;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.TimeUnit;\n\npublic class LinkisClientTest {\n\n    public static void main(String[] args){\n\n        String user = &quot;hadoop&quot;;\n        String executeCode = &quot;show databases;&quot;;\n\n        // 1. Configure DWSClientBuilder, get a DWSClientConfig through DWSClientBuilder\n        DWSClientConfig clientConfig = ((DWSClientConfigBuilder) (DWSClientConfigBuilder.newBuilder()\n                .addServerUrl(&quot;http://${ip}:${port}&quot;)  //Specify ServerUrl, the address of the linkis gateway, such as http://{ip}:{port}\n                .connectionTimeout(30000)   //connectionTimeOut Client connection timeout\n                .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES)  //Whether to enable registration discovery, if enabled, the newly launched Gateway will be automatically discovered\n                .loadbalancerEnabled(true)  // Whether to enable load balancing, if registration discovery is not enabled, load balancing is meaningless\n                .maxConnectionSize(5)   //Specify the maximum number of connections, that is, the maximum number of concurrent\n                .retryEnabled(false).readTimeout(30000)   //Execution failed, whether to allow retry\n                .setAuthenticationStrategy(new StaticAuthenticationStrategy())   //AuthenticationStrategy Linkis login authentication method\n                .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;)))  //Authentication key, generally the user name; authentication value, generally the password corresponding to the user name\n                .setDWSVersion(&quot;v1&quot;).build();  //The version of the linkis backend protocol, the current version is v1\n\n        // 2. Obtain a UJESClient through DWSClientConfig\n        UJESClient client = new UJESClientImpl(clientConfig);\n\n        try {\n            // 3. Start code execution\n            System.out.println(&quot;user : &quot; + user + &quot;, code : [&quot; + executeCode + &quot;]&quot;);\n            Map&lt;String, Object&gt; startupMap = new HashMap&lt;String, Object&gt;();\n            startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;default&quot;); // A variety of startup parameters can be stored in startupMap, see linkis management console configuration\n            JobExecuteResult jobExecuteResult = client.execute(JobExecuteAction.builder()\n                    .setCreator(&quot;linkisClient-Test&quot;)  //creator，the system name of the client requesting linkis, used for system-level isolation\n                    .addExecuteCode(executeCode)   //ExecutionCode Requested code\n                    .setEngineType((JobExecuteAction.EngineType) JobExecuteAction.EngineType$.MODULE$.HIVE()) // The execution engine type of the linkis that you want to request, such as Spark hive, etc.\n                    .setUser(user)   //User，Requesting users; used for user-level multi-tenant isolation\n                    .setStartupParams(startupMap)\n                    .build());\n            System.out.println(&quot;execId: &quot; + jobExecuteResult.getExecID() + &quot;, taskId: &quot; + jobExecuteResult.taskID());\n\n            // 4. Get the execution status of the script\n            JobInfoResult jobInfoResult = client.getJobInfo(jobExecuteResult);\n            int sleepTimeMills = 1000;\n            while(!jobInfoResult.isCompleted()) {\n                // 5. Get the execution progress of the script\n                JobProgressResult progress = client.progress(jobExecuteResult);\n                Utils.sleepQuietly(sleepTimeMills);\n                jobInfoResult = client.getJobInfo(jobExecuteResult);\n            }\n\n            // 6. Get the job information of the script\n            JobInfoResult jobInfo = client.getJobInfo(jobExecuteResult);\n            // 7. Get a list of result sets (if the user submits multiple SQL at a time, multiple result sets will be generated)\n            String resultSet = jobInfo.getResultSetList(client)[0];\n            // 8. Get a specific result set through a result set information\n            Object fileContents = client.resultSet(ResultSetAction.builder().setPath(resultSet).setUser(jobExecuteResult.getUser()).build()).getFileContent();\n            System.out.println(&quot;fileContents: &quot; + fileContents);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n            IOUtils.closeQuietly(client);\n        }\n        IOUtils.closeQuietly(client);\n    }\n}\n</code></pre><p>Run the above code to interact with Linkis</p><h3>3. Scala test code:</h3><pre><code class="language-scala">package com.webank.wedatasphere.linkis.client.test\n\nimport java.util.concurrent.TimeUnit\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobExecuteAction.EngineType\nimport com.webank.wedatasphere.linkis.ujes.client.request.{JobExecuteAction, ResultSetAction}\nimport org.apache.commons.io.IOUtils\n\nobject LinkisClientImplTest extends App {\n\n  var executeCode = &quot;show databases;&quot;\n  var user = &quot;hadoop&quot;\n\n  // 1. Configure DWSClientBuilder, get a DWSClientConfig through DWSClientBuilder\n  val clientConfig = DWSClientConfigBuilder.newBuilder()\n    .addServerUrl(&quot;http://${ip}:${port}&quot;) //Specify ServerUrl, the address of the Linkis server-side gateway, such as http://{ip}:{port}\n    .connectionTimeout(30000) //connectionTimeOut client connection timeout\n    .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES) //Whether to enable registration discovery, if enabled, the newly launched Gateway will be automatically discovered\n    .loadbalancerEnabled(true) // Whether to enable load balancing, if registration discovery is not enabled, load balancing is meaningless\n    .maxConnectionSize(5) //Specify the maximum number of connections, that is, the maximum number of concurrent\n    .retryEnabled(false).readTimeout(30000) //execution failed, whether to allow retry\n    .setAuthenticationStrategy(new StaticAuthenticationStrategy()) //AuthenticationStrategy Linkis authentication method\n    .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;) //Authentication key, generally the user name; authentication value, generally the password corresponding to the user name\n    .setDWSVersion(&quot;v1&quot;).build() //Linkis backend protocol version, the current version is v1\n\n  // 2. Get a UJESClient through DWSClientConfig\n  val client = UJESClient(clientConfig)\n  \n  try {\n    // 3. Start code execution\n    println(&quot;user: &quot;+ user + &quot;, code: [&quot; + executeCode + &quot;]&quot;)\n    val startupMap = new java.util.HashMap[String, Any]()\n    startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;default&quot;) //Startup parameter configuration\n    val jobExecuteResult = client.execute(JobExecuteAction.builder()\n      .setCreator(&quot;LinkisClient-Test&quot;) //creator, requesting the system name of the Linkis client, used for system-level isolation\n      .addExecuteCode(executeCode) //ExecutionCode The code to be executed\n      .setEngineType(EngineType.SPARK) // The execution engine type of Linkis that you want to request, such as Spark hive, etc.\n      .setStartupParams(startupMap)\n      .setUser(user).build()) //User, request user; used for user-level multi-tenant isolation\n    println(&quot;execId: &quot;+ jobExecuteResult.getExecID + &quot;, taskId:&quot; + jobExecuteResult.taskID)\n    \n    // 4. Get the execution status of the script\n    var jobInfoResult = client.getJobInfo(jobExecuteResult)\n    val sleepTimeMills: Int = 1000\n    while (!jobInfoResult.isCompleted) {\n      // 5. Get the execution progress of the script\n      val progress = client.progress(jobExecuteResult)\n      val progressInfo = if (progress.getProgressInfo != null) progress.getProgressInfo.toList else List.empty\n      println(&quot;progress: &quot;+ progress.getProgress + &quot;, progressInfo:&quot; + progressInfo)\n      Utils.sleepQuietly(sleepTimeMills)\n      jobInfoResult = client.getJobInfo(jobExecuteResult)\n    }\n    if (!jobInfoResult.isSucceed) {\n      println(&quot;Failed to execute job: &quot;+ jobInfoResult.getMessage)\n      throw new Exception(jobInfoResult.getMessage)\n    }\n\n    // 6. Get the job information of the script\n    val jobInfo = client.getJobInfo(jobExecuteResult)\n    // 7. Get the list of result sets (if the user submits multiple SQL at a time, multiple result sets will be generated)\n    val resultSetList = jobInfoResult.getResultSetList(client)\n    println(&quot;All result set list:&quot;)\n    resultSetList.foreach(println)\n    val oneResultSet = jobInfo.getResultSetList(client).head\n    // 8. Get a specific result set through a result set information\n    val fileContents = client.resultSet(ResultSetAction.builder().setPath(oneResultSet).setUser(jobExecuteResult.getUser).build()).getFileContent\n    println(&quot;First fileContents: &quot;)\n    println(fileContents)\n  } catch {\n    case e: Exception =&gt; {\n      e.printStackTrace()\n    }\n  }\n  IOUtils.closeQuietly(client)\n}\n</code></pre><h2>3. Linkis1.0 new submit interface with Label support</h2><p>Linkis1.0 adds the client.submit method, which is used to adapt with the new task execution interface of 1.0, and supports the input of Label and other parameters</p><h3>3.1 Java Test Class</h3><pre><code class="language-java">package com.webank.wedatasphere.linkis.client.test;\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfig;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder;\nimport com.webank.wedatasphere.linkis.manager.label.constant.LabelKeyConstant;\nimport com.webank.wedatasphere.linkis.protocol.constants.TaskConstant;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClientImpl;\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobSubmitAction;\nimport com.webank.wedatasphere.linkis.ujes.client.request.ResultSetAction;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobExecuteResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobInfoResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobProgressResult;\nimport org.apache.commons.io.IOUtils;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.TimeUnit;\n\npublic class JavaClientTest {\n\n    public static void main(String[] args){\n\n        String user = &quot;hadoop&quot;;\n        String executeCode = &quot;show tables&quot;;\n\n        // 1. Configure ClientBuilder and get ClientConfig\n        DWSClientConfig clientConfig = ((DWSClientConfigBuilder) (DWSClientConfigBuilder.newBuilder()\n                .addServerUrl(&quot;http://${ip}:${port}&quot;) //Specify ServerUrl, the address of the linkis server-side gateway, such as http://{ip}:{port}\n                .connectionTimeout(30000) //connectionTimeOut client connection timeout\n                .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES) //Whether to enable registration discovery, if enabled, the newly launched Gateway will be automatically discovered\n                .loadbalancerEnabled(true) // Whether to enable load balancing, if registration discovery is not enabled, load balancing is meaningless\n                .maxConnectionSize(5) //Specify the maximum number of connections, that is, the maximum number of concurrent\n                .retryEnabled(false).readTimeout(30000) //execution failed, whether to allow retry\n                .setAuthenticationStrategy(new StaticAuthenticationStrategy()) //AuthenticationStrategy Linkis authentication method\n                .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;))) //Authentication key, generally the user name; authentication value, generally the password corresponding to the user name\n                .setDWSVersion(&quot;v1&quot;).build(); //Linkis background protocol version, the current version is v1\n\n        // 2. Get a UJESClient through DWSClientConfig\n        UJESClient client = new UJESClientImpl(clientConfig);\n\n        try {\n            // 3. Start code execution\n            System.out.println(&quot;user: &quot;+ user + &quot;, code: [&quot; + executeCode + &quot;]&quot;);\n            Map&lt;String, Object&gt; startupMap = new HashMap&lt;String, Object&gt;();\n            // A variety of startup parameters can be stored in startupMap, see linkis management console configuration\n            startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;q02&quot;);\n            //Specify Label\n            Map&lt;String, Object&gt; labels = new HashMap&lt;String, Object&gt;();\n            //Add the label that this execution depends on: EngineTypeLabel/UserCreatorLabel/EngineRunTypeLabel\n            labels.put(LabelKeyConstant.ENGINE_TYPE_KEY, &quot;hive-1.2.1&quot;);\n            labels.put(LabelKeyConstant.USER_CREATOR_TYPE_KEY, &quot;hadoop-IDE&quot;);\n            labels.put(LabelKeyConstant.ENGINE_RUN_TYPE_KEY, &quot;hql&quot;);\n            //Specify source\n            Map&lt;String, Object&gt; source = new HashMap&lt;String, Object&gt;();\n            source.put(TaskConstant.SCRIPTPATH, &quot;LinkisClient-test&quot;);\n            JobExecuteResult jobExecuteResult = client.submit( JobSubmitAction.builder()\n                    .addExecuteCode(executeCode)\n                    .setStartupParams(startupMap)\n                    .setUser(user)//Job submit user\n                    .addExecuteUser(user)//The actual execution user\n                    .setLabels(labels)\n                    .setSource(source)\n                    .build()\n            );\n            System.out.println(&quot;execId: &quot;+ jobExecuteResult.getExecID() + &quot;, taskId:&quot; + jobExecuteResult.taskID());\n\n            // 4. Get the execution status of the script\n            JobInfoResult jobInfoResult = client.getJobInfo(jobExecuteResult);\n            int sleepTimeMills = 1000;\n            while(!jobInfoResult.isCompleted()) {\n                // 5. Get the execution progress of the script\n                JobProgressResult progress = client.progress(jobExecuteResult);\n                Utils.sleepQuietly(sleepTimeMills);\n                jobInfoResult = client.getJobInfo(jobExecuteResult);\n            }\n\n            // 6. Get the job information of the script\n            JobInfoResult jobInfo = client.getJobInfo(jobExecuteResult);\n            // 7. Get the list of result sets (if the user submits multiple SQL at a time, multiple result sets will be generated)\n            String resultSet = jobInfo.getResultSetList(client)[0];\n            // 8. Get a specific result set through a result set information\n            Object fileContents = client.resultSet(ResultSetAction.builder().setPath(resultSet).setUser(jobExecuteResult.getUser()).build()).getFileContent();\n            System.out.println(&quot;fileContents: &quot;+ fileContents);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n            IOUtils.closeQuietly(client);\n        }\n        IOUtils.closeQuietly(client);\n    }\n}\n\n</code></pre><h3>3.2 Scala Test Class</h3><pre><code class="language-scala">package com.webank.wedatasphere.linkis.client.test\n\nimport java.util\nimport java.util.concurrent.TimeUnit\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder\nimport com.webank.wedatasphere.linkis.manager.label.constant.LabelKeyConstant\nimport com.webank.wedatasphere.linkis.protocol.constants.TaskConstant\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient\nimport com.webank.wedatasphere.linkis.ujes.client.request.{JobSubmitAction, ResultSetAction}\nimport org.apache.commons.io.IOUtils\n\n\nobject ScalaClientTest {\n\n  def main(args: Array[String]): Unit = {\n    val executeCode = &quot;show tables&quot;\n    val user = &quot;hadoop&quot;\n\n    // 1. Configure DWSClientBuilder, get a DWSClientConfig through DWSClientBuilder\n    val clientConfig = DWSClientConfigBuilder.newBuilder()\n      .addServerUrl(&quot;http://${ip}:${port}&quot;) //Specify ServerUrl, the address of the Linkis server-side gateway, such as http://{ip}:{port}\n      .connectionTimeout(30000) //connectionTimeOut client connection timeout\n      .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES) //Whether to enable registration discovery, if enabled, the newly launched Gateway will be automatically discovered\n      .loadbalancerEnabled(true) // Whether to enable load balancing, if registration discovery is not enabled, load balancing is meaningless\n      .maxConnectionSize(5) //Specify the maximum number of connections, that is, the maximum number of concurrent\n      .retryEnabled(false).readTimeout(30000) //execution failed, whether to allow retry\n      .setAuthenticationStrategy(new StaticAuthenticationStrategy()) //AuthenticationStrategy Linkis authentication method\n      .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;) //Authentication key, generally the user name; authentication value, generally the password corresponding to the user name\n      .setDWSVersion(&quot;v1&quot;).build() //Linkis backend protocol version, the current version is v1\n\n    // 2. Get a UJESClient through DWSClientConfig\n    val client = UJESClient(clientConfig)\n\n    try {\n      // 3. Start code execution\n      println(&quot;user: &quot;+ user + &quot;, code: [&quot; + executeCode + &quot;]&quot;)\n      val startupMap = new java.util.HashMap[String, Any]()\n      startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;q02&quot;) //Startup parameter configuration\n      //Specify Label\n      val labels: util.Map[String, Any] = new util.HashMap[String, Any]\n      //Add the label that this execution depends on, such as engineLabel\n      labels.put(LabelKeyConstant.ENGINE_TYPE_KEY, &quot;hive-1.2.1&quot;)\n      labels.put(LabelKeyConstant.USER_CREATOR_TYPE_KEY, &quot;hadoop-IDE&quot;)\n      labels.put(LabelKeyConstant.ENGINE_RUN_TYPE_KEY, &quot;hql&quot;)\n      //Specify source\n      val source: util.Map[String, Any] = new util.HashMap[String, Any]\n      source.put(TaskConstant.SCRIPTPATH, &quot;LinkisClient-test&quot;)\n      val jobExecuteResult = client.submit(JobSubmitAction.builder\n          .addExecuteCode(executeCode)\n          .setStartupParams(startupMap)\n          .setUser(user) //Job submit user\n          .addExecuteUser(user) //The actual execution user\n          .setLabels(labels)\n          .setSource(source)\n          .build) //User, requesting user; used for user-level multi-tenant isolation\n      println(&quot;execId: &quot;+ jobExecuteResult.getExecID + &quot;, taskId:&quot; + jobExecuteResult.taskID)\n\n      // 4. Get the execution status of the script\n      var jobInfoResult = client.getJobInfo(jobExecuteResult)\n      val sleepTimeMills: Int = 1000\n      while (!jobInfoResult.isCompleted) {\n        // 5. Get the execution progress of the script\n        val progress = client.progress(jobExecuteResult)\n        val progressInfo = if (progress.getProgressInfo != null) progress.getProgressInfo.toList else List.empty\n        println(&quot;progress: &quot;+ progress.getProgress + &quot;, progressInfo:&quot; + progressInfo)\n        Utils.sleepQuietly(sleepTimeMills)\n        jobInfoResult = client.getJobInfo(jobExecuteResult)\n      }\n      if (!jobInfoResult.isSucceed) {\n        println(&quot;Failed to execute job: &quot;+ jobInfoResult.getMessage)\n        throw new Exception(jobInfoResult.getMessage)\n      }\n\n      // 6. Get the job information of the script\n      val jobInfo = client.getJobInfo(jobExecuteResult)\n      // 7. Get the list of result sets (if the user submits multiple SQL at a time, multiple result sets will be generated)\n      val resultSetList = jobInfoResult.getResultSetList(client)\n      println(&quot;All result set list:&quot;)\n      resultSetList.foreach(println)\n      val oneResultSet = jobInfo.getResultSetList(client).head\n      // 8. Get a specific result set through a result set information\n      val fileContents = client.resultSet(ResultSetAction.builder().setPath(oneResultSet).setUser(jobExecuteResult.getUser).build()).getFileContent\n      println(&quot;First fileContents: &quot;)\n      println(fileContents)\n    } catch {\n      case e: Exception =&gt; {\n        e.printStackTrace()\n      }\n    }\n    IOUtils.closeQuietly(client)\n  }\n\n}\n\n</code></pre>',17)],u={setup:(n,{expose:i})=>(i({frontmatter:{}}),(n,i)=>(e(),t("div",l,a)))},r={class:"markdown-body"},c=[n('<blockquote><p>Linkis 提供了方便的JAVA和SCALA调用的接口，只需要引入linkis-computation-client的模块就可以进行使用，1.0后新增支持带Label提交的方式，下面将对兼容0.X的方式和1.0新增的方式进行介绍</p></blockquote><h2>1. 引入依赖模块</h2><pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;com.webank.wedatasphere.linkis&lt;/groupId&gt;\n  &lt;artifactId&gt;linkis-computation-client&lt;/artifactId&gt;\n  &lt;version&gt;${linkis.version}&lt;/version&gt;\n&lt;/dependency&gt;\n如：\n&lt;dependency&gt;\n  &lt;groupId&gt;com.webank.wedatasphere.linkis&lt;/groupId&gt;\n  &lt;artifactId&gt;linkis-computation-client&lt;/artifactId&gt;\n  &lt;version&gt;1.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><h2>2. 兼容0.X的Execute方法提交</h2><h3>2.1 Java测试代码</h3><p>建立Java的测试类UJESClientImplTestJ，具体接口含义可以见注释：</p><pre><code class="language-java">package com.webank.wedatasphere.linkis.client.test;\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.TokenAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfig;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClientImpl;\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobExecuteAction;\nimport com.webank.wedatasphere.linkis.ujes.client.request.ResultSetAction;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobExecuteResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobInfoResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobProgressResult;\nimport org.apache.commons.io.IOUtils;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.TimeUnit;\n\npublic class LinkisClientTest {\n\n    public static void main(String[] args){\n\n        String user = &quot;hadoop&quot;;\n        String executeCode = &quot;show databases;&quot;;\n\n        // 1. 配置DWSClientBuilder，通过DWSClientBuilder获取一个DWSClientConfig\n        DWSClientConfig clientConfig = ((DWSClientConfigBuilder) (DWSClientConfigBuilder.newBuilder()\n                .addServerUrl(&quot;http://${ip}:${port}&quot;)  //指定ServerUrl，linkis服务器端网关的地址,如http://{ip}:{port}\n                .connectionTimeout(30000)   //connectionTimeOut 客户端连接超时时间\n                .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES)  //是否启用注册发现，如果启用，会自动发现新启动的Gateway \n                .loadbalancerEnabled(true)  // 是否启用负载均衡，如果不启用注册发现，则负载均衡没有意义\n                .maxConnectionSize(5)   //指定最大连接数，即最大并发数\n                .retryEnabled(false).readTimeout(30000)   //执行失败，是否允许重试\n                .setAuthenticationStrategy(new StaticAuthenticationStrategy())   //AuthenticationStrategy Linkis认证方式\n                .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;)))  //认证key，一般为用户名;  认证value，一般为用户名对应的密码\n                .setDWSVersion(&quot;v1&quot;).build();  //linkis后台协议的版本，当前版本为v1\n\n        // 2. 通过DWSClientConfig获取一个UJESClient\n        UJESClient client = new UJESClientImpl(clientConfig);\n\n        try {\n            // 3. 开始执行代码\n            System.out.println(&quot;user : &quot; + user + &quot;, code : [&quot; + executeCode + &quot;]&quot;);\n            Map&lt;String, Object&gt; startupMap = new HashMap&lt;String, Object&gt;();\n            startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;default&quot;); // 在startupMap可以存放多种启动参数，参见linkis管理台配置\n            JobExecuteResult jobExecuteResult = client.execute(JobExecuteAction.builder()\n                    .setCreator(&quot;linkisClient-Test&quot;)  //creator，请求linkis的客户端的系统名，用于做系统级隔离\n                    .addExecuteCode(executeCode)   //ExecutionCode 请求执行的代码\n                    .setEngineType((JobExecuteAction.EngineType) JobExecuteAction.EngineType$.MODULE$.HIVE()) // 希望请求的linkis的执行引擎类型，如Spark hive等\n                    .setUser(user)   //User，请求用户；用于做用户级多租户隔离\n                    .setStartupParams(startupMap)\n                    .build());\n            System.out.println(&quot;execId: &quot; + jobExecuteResult.getExecID() + &quot;, taskId: &quot; + jobExecuteResult.taskID());\n\n            // 4. 获取脚本的执行状态\n            JobInfoResult jobInfoResult = client.getJobInfo(jobExecuteResult);\n            int sleepTimeMills = 1000;\n            while(!jobInfoResult.isCompleted()) {\n                // 5. 获取脚本的执行进度\n                JobProgressResult progress = client.progress(jobExecuteResult);\n                Utils.sleepQuietly(sleepTimeMills);\n                jobInfoResult = client.getJobInfo(jobExecuteResult);\n            }\n\n            // 6. 获取脚本的Job信息\n            JobInfoResult jobInfo = client.getJobInfo(jobExecuteResult);\n            // 7. 获取结果集列表（如果用户一次提交多个SQL，会产生多个结果集）\n            String resultSet = jobInfo.getResultSetList(client)[0];\n            // 8. 通过一个结果集信息，获取具体的结果集\n            Object fileContents = client.resultSet(ResultSetAction.builder().setPath(resultSet).setUser(jobExecuteResult.getUser()).build()).getFileContent();\n            System.out.println(&quot;fileContents: &quot; + fileContents);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n            IOUtils.closeQuietly(client);\n        }\n        IOUtils.closeQuietly(client);\n    }\n}\n</code></pre><p>运行上述的代码即可以和Linkis进行交互</p><h3>3. Scala测试代码：</h3><pre><code class="language-scala">package com.webank.wedatasphere.linkis.client.test\n\nimport java.util.concurrent.TimeUnit\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobExecuteAction.EngineType\nimport com.webank.wedatasphere.linkis.ujes.client.request.{JobExecuteAction, ResultSetAction}\nimport org.apache.commons.io.IOUtils\n\nobject LinkisClientImplTest extends App {\n\n  var executeCode = &quot;show databases;&quot;\n  var user = &quot;hadoop&quot;\n\n  // 1. 配置DWSClientBuilder，通过DWSClientBuilder获取一个DWSClientConfig\n  val clientConfig = DWSClientConfigBuilder.newBuilder()\n    .addServerUrl(&quot;http://${ip}:${port}&quot;)  //指定ServerUrl，Linkis服务器端网关的地址,如http://{ip}:{port}\n    .connectionTimeout(30000)  //connectionTimeOut 客户端连接超时时间\n    .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES)  //是否启用注册发现，如果启用，会自动发现新启动的Gateway\n    .loadbalancerEnabled(true)  // 是否启用负载均衡，如果不启用注册发现，则负载均衡没有意义\n    .maxConnectionSize(5)   //指定最大连接数，即最大并发数\n    .retryEnabled(false).readTimeout(30000)   //执行失败，是否允许重试\n    .setAuthenticationStrategy(new StaticAuthenticationStrategy())  //AuthenticationStrategy Linkis认证方式\n    .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;)  //认证key，一般为用户名;  认证value，一般为用户名对应的密码\n    .setDWSVersion(&quot;v1&quot;).build()  //Linkis后台协议的版本，当前版本为v1\n\n  // 2. 通过DWSClientConfig获取一个UJESClient\n  val client = UJESClient(clientConfig)\n  \n  try {\n    // 3. 开始执行代码\n    println(&quot;user : &quot; + user + &quot;, code : [&quot; + executeCode + &quot;]&quot;)\n    val startupMap = new java.util.HashMap[String, Any]()\n    startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;default&quot;) //启动参数配置\n    val jobExecuteResult = client.execute(JobExecuteAction.builder()\n      .setCreator(&quot;LinkisClient-Test&quot;)  //creator，请求Linkis的客户端的系统名，用于做系统级隔离\n      .addExecuteCode(executeCode)   //ExecutionCode 请求执行的代码\n      .setEngineType(EngineType.SPARK) // 希望请求的Linkis的执行引擎类型，如Spark hive等\n      .setStartupParams(startupMap)\n      .setUser(user).build())  //User，请求用户；用于做用户级多租户隔离\n    println(&quot;execId: &quot; + jobExecuteResult.getExecID + &quot;, taskId: &quot; + jobExecuteResult.taskID)\n    \n    // 4. 获取脚本的执行状态\n    var jobInfoResult = client.getJobInfo(jobExecuteResult)\n    val sleepTimeMills : Int = 1000\n    while (!jobInfoResult.isCompleted) {\n      // 5. 获取脚本的执行进度   \n      val progress = client.progress(jobExecuteResult)\n      val progressInfo = if (progress.getProgressInfo != null) progress.getProgressInfo.toList else List.empty\n      println(&quot;progress: &quot; + progress.getProgress + &quot;, progressInfo: &quot; + progressInfo)\n      Utils.sleepQuietly(sleepTimeMills)\n      jobInfoResult = client.getJobInfo(jobExecuteResult)\n    }\n    if (!jobInfoResult.isSucceed) {\n      println(&quot;Failed to execute job: &quot; + jobInfoResult.getMessage)\n      throw new Exception(jobInfoResult.getMessage)\n    }\n\n    // 6. 获取脚本的Job信息\n    val jobInfo = client.getJobInfo(jobExecuteResult)\n    // 7. 获取结果集列表（如果用户一次提交多个SQL，会产生多个结果集）\n    val resultSetList = jobInfoResult.getResultSetList(client)\n    println(&quot;All result set list:&quot;)\n    resultSetList.foreach(println)\n    val oneResultSet = jobInfo.getResultSetList(client).head\n    // 8. 通过一个结果集信息，获取具体的结果集\n    val fileContents = client.resultSet(ResultSetAction.builder().setPath(oneResultSet).setUser(jobExecuteResult.getUser).build()).getFileContent\n    println(&quot;First fileContents: &quot;)\n    println(fileContents)\n  } catch {\n    case e: Exception =&gt; {\n      e.printStackTrace()\n    }\n  }\n  IOUtils.closeQuietly(client)\n}\n</code></pre><h2>3. 1.0新增的支持带Label提交的Submit方式</h2><p>1.0 新增了client.submit方法，用于对接1.0新的任务执行接口，支持传入Label等参数</p><h3>3.1 Java测试类</h3><pre><code>package com.webank.wedatasphere.linkis.client.test;\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils;\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfig;\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder;\nimport com.webank.wedatasphere.linkis.manager.label.constant.LabelKeyConstant;\nimport com.webank.wedatasphere.linkis.protocol.constants.TaskConstant;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient;\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClientImpl;\nimport com.webank.wedatasphere.linkis.ujes.client.request.JobSubmitAction;\nimport com.webank.wedatasphere.linkis.ujes.client.request.ResultSetAction;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobExecuteResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobInfoResult;\nimport com.webank.wedatasphere.linkis.ujes.client.response.JobProgressResult;\nimport org.apache.commons.io.IOUtils;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.TimeUnit;\n\npublic class JavaClientTest {\n\n    public static void main(String[] args){\n\n        String user = &quot;hadoop&quot;;\n        String executeCode = &quot;show tables&quot;;\n\n        // 1. 配置ClientBuilder，获取ClientConfig\n        DWSClientConfig clientConfig = ((DWSClientConfigBuilder) (DWSClientConfigBuilder.newBuilder()\n                .addServerUrl(&quot;http://${ip}:${port}&quot;)  //指定ServerUrl，linkis服务器端网关的地址,如http://{ip}:{port}\n                .connectionTimeout(30000)   //connectionTimeOut 客户端连接超时时间\n                .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES)  //是否启用注册发现，如果启用，会自动发现新启动的Gateway\n                .loadbalancerEnabled(true)  // 是否启用负载均衡，如果不启用注册发现，则负载均衡没有意义\n                .maxConnectionSize(5)   //指定最大连接数，即最大并发数\n                .retryEnabled(false).readTimeout(30000)   //执行失败，是否允许重试\n                .setAuthenticationStrategy(new StaticAuthenticationStrategy())   //AuthenticationStrategy Linkis认证方式\n                .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;)))  //认证key，一般为用户名;  认证value，一般为用户名对应的密码\n                .setDWSVersion(&quot;v1&quot;).build();  //linkis后台协议的版本，当前版本为v1\n\n        // 2. 通过DWSClientConfig获取一个UJESClient\n        UJESClient client = new UJESClientImpl(clientConfig);\n\n        try {\n            // 3. 开始执行代码\n            System.out.println(&quot;user : &quot; + user + &quot;, code : [&quot; + executeCode + &quot;]&quot;);\n            Map&lt;String, Object&gt; startupMap = new HashMap&lt;String, Object&gt;();\n            // 在startupMap可以存放多种启动参数，参见linkis管理台配置\n            startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;q02&quot;);\n            //指定Label\n            Map&lt;String, Object&gt; labels = new HashMap&lt;String, Object&gt;();\n            //添加本次执行所依赖的的标签:EngineTypeLabel/UserCreatorLabel/EngineRunTypeLabel\n            labels.put(LabelKeyConstant.ENGINE_TYPE_KEY, &quot;hive-1.2.1&quot;);\n            labels.put(LabelKeyConstant.USER_CREATOR_TYPE_KEY, &quot;hadoop-IDE&quot;);\n            labels.put(LabelKeyConstant.CODE_TYPE_KEY, &quot;hql&quot;);\n            //指定source\n            Map&lt;String, Object&gt; source = new HashMap&lt;String, Object&gt;();\n            source.put(TaskConstant.SCRIPTPATH, &quot;LinkisClient-test&quot;);\n            JobExecuteResult jobExecuteResult = client.submit( JobSubmitAction.builder()\n                    .addExecuteCode(executeCode)\n                    .setStartupParams(startupMap)\n                    .setUser(user)//Job提交用户\n                    .addExecuteUser(user)//实际执行用户\n                    .setLabels(labels)\n                    .setSource(source)\n                    .build()\n            );\n            System.out.println(&quot;execId: &quot; + jobExecuteResult.getExecID() + &quot;, taskId: &quot; + jobExecuteResult.taskID());\n\n            // 4. 获取脚本的执行状态\n            JobInfoResult jobInfoResult = client.getJobInfo(jobExecuteResult);\n            int sleepTimeMills = 1000;\n            while(!jobInfoResult.isCompleted()) {\n                // 5. 获取脚本的执行进度\n                JobProgressResult progress = client.progress(jobExecuteResult);\n                Utils.sleepQuietly(sleepTimeMills);\n                jobInfoResult = client.getJobInfo(jobExecuteResult);\n            }\n\n            // 6. 获取脚本的Job信息\n            JobInfoResult jobInfo = client.getJobInfo(jobExecuteResult);\n            // 7. 获取结果集列表（如果用户一次提交多个SQL，会产生多个结果集）\n            String resultSet = jobInfo.getResultSetList(client)[0];\n            // 8. 通过一个结果集信息，获取具体的结果集\n            Object fileContents = client.resultSet(ResultSetAction.builder().setPath(resultSet).setUser(jobExecuteResult.getUser()).build()).getFileContent();\n            System.out.println(&quot;fileContents: &quot; + fileContents);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n            IOUtils.closeQuietly(client);\n        }\n        IOUtils.closeQuietly(client);\n    }\n}\n\n</code></pre><h3>3.2 Scala 测试类</h3><pre><code>package com.webank.wedatasphere.linkis.client.test\n\nimport java.util\nimport java.util.concurrent.TimeUnit\n\nimport com.webank.wedatasphere.linkis.common.utils.Utils\nimport com.webank.wedatasphere.linkis.httpclient.dws.authentication.StaticAuthenticationStrategy\nimport com.webank.wedatasphere.linkis.httpclient.dws.config.DWSClientConfigBuilder\nimport com.webank.wedatasphere.linkis.manager.label.constant.LabelKeyConstant\nimport com.webank.wedatasphere.linkis.protocol.constants.TaskConstant\nimport com.webank.wedatasphere.linkis.ujes.client.UJESClient\nimport com.webank.wedatasphere.linkis.ujes.client.request.{JobSubmitAction, ResultSetAction}\nimport org.apache.commons.io.IOUtils\n\n\nobject ScalaClientTest {\n\n  def main(args: Array[String]): Unit = {\n    val executeCode = &quot;show tables&quot;\n    val user = &quot;hadoop&quot;\n\n    // 1. 配置DWSClientBuilder，通过DWSClientBuilder获取一个DWSClientConfig\n    val clientConfig = DWSClientConfigBuilder.newBuilder()\n      .addServerUrl(&quot;http://${ip}:${port}&quot;) //指定ServerUrl，Linkis服务器端网关的地址,如http://{ip}:{port}\n      .connectionTimeout(30000)  //connectionTimeOut 客户端连接超时时间\n      .discoveryEnabled(false).discoveryFrequency(1, TimeUnit.MINUTES)  //是否启用注册发现，如果启用，会自动发现新启动的Gateway\n      .loadbalancerEnabled(true)  // 是否启用负载均衡，如果不启用注册发现，则负载均衡没有意义\n      .maxConnectionSize(5)   //指定最大连接数，即最大并发数\n      .retryEnabled(false).readTimeout(30000)   //执行失败，是否允许重试\n      .setAuthenticationStrategy(new StaticAuthenticationStrategy())  //AuthenticationStrategy Linkis认证方式\n      .setAuthTokenKey(&quot;${username}&quot;).setAuthTokenValue(&quot;${password}&quot;) //认证key，一般为用户名;  认证value，一般为用户名对应的密码\n      .setDWSVersion(&quot;v1&quot;).build()  //Linkis后台协议的版本，当前版本为v1\n\n    // 2. 通过DWSClientConfig获取一个UJESClient\n    val client = UJESClient(clientConfig)\n\n    try {\n      // 3. 开始执行代码\n      println(&quot;user : &quot; + user + &quot;, code : [&quot; + executeCode + &quot;]&quot;)\n      val startupMap = new java.util.HashMap[String, Any]()\n      startupMap.put(&quot;wds.linkis.yarnqueue&quot;, &quot;q02&quot;) //启动参数配置\n      //指定Label\n      val labels: util.Map[String, Any] = new util.HashMap[String, Any]\n      //添加本次执行所依赖的的标签，如engineLabel\n      labels.put(LabelKeyConstant.ENGINE_TYPE_KEY, &quot;hive-1.2.1&quot;)\n      labels.put(LabelKeyConstant.USER_CREATOR_TYPE_KEY, &quot;hadoop-IDE&quot;)\n      labels.put(LabelKeyConstant.CODE_TYPE_KEY, &quot;hql&quot;)\n      //指定source\n      val source: util.Map[String, Any] = new util.HashMap[String, Any]\n      source.put(TaskConstant.SCRIPTPATH, &quot;LinkisClient-test&quot;)\n      val jobExecuteResult = client.submit(JobSubmitAction.builder\n          .addExecuteCode(executeCode)\n          .setStartupParams(startupMap)\n          .setUser(user) //Job提交用户\n          .addExecuteUser(user) //实际执行用户\n          .setLabels(labels)\n          .setSource(source)\n          .build)  //User，请求用户；用于做用户级多租户隔离\n      println(&quot;execId: &quot; + jobExecuteResult.getExecID + &quot;, taskId: &quot; + jobExecuteResult.taskID)\n\n      // 4. 获取脚本的执行状态\n      var jobInfoResult = client.getJobInfo(jobExecuteResult)\n      val sleepTimeMills : Int = 1000\n      while (!jobInfoResult.isCompleted) {\n        // 5. 获取脚本的执行进度\n        val progress = client.progress(jobExecuteResult)\n        val progressInfo = if (progress.getProgressInfo != null) progress.getProgressInfo.toList else List.empty\n        println(&quot;progress: &quot; + progress.getProgress + &quot;, progressInfo: &quot; + progressInfo)\n        Utils.sleepQuietly(sleepTimeMills)\n        jobInfoResult = client.getJobInfo(jobExecuteResult)\n      }\n      if (!jobInfoResult.isSucceed) {\n        println(&quot;Failed to execute job: &quot; + jobInfoResult.getMessage)\n        throw new Exception(jobInfoResult.getMessage)\n      }\n\n      // 6. 获取脚本的Job信息\n      val jobInfo = client.getJobInfo(jobExecuteResult)\n      // 7. 获取结果集列表（如果用户一次提交多个SQL，会产生多个结果集）\n      val resultSetList = jobInfoResult.getResultSetList(client)\n      println(&quot;All result set list:&quot;)\n      resultSetList.foreach(println)\n      val oneResultSet = jobInfo.getResultSetList(client).head\n      // 8. 通过一个结果集信息，获取具体的结果集\n      val fileContents = client.resultSet(ResultSetAction.builder().setPath(oneResultSet).setUser(jobExecuteResult.getUser).build()).getFileContent\n      println(&quot;First fileContents: &quot;)\n      println(fileContents)\n    } catch {\n      case e: Exception =&gt; {\n        e.printStackTrace()\n      }\n    }\n    IOUtils.closeQuietly(client)\n  }\n\n}\n\n</code></pre>',16)],p={setup:(n,{expose:i})=>(i({frontmatter:{}}),(n,i)=>(e(),t("div",r,c)))},d={setup(t){const n=i(localStorage.getItem("locale")||"en");return(t,i)=>"en"===n.value?(e(),o(s(u),{key:0})):(e(),o(s(p),{key:1}))}};export{d as default};
